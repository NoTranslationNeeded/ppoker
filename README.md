# Glacial Supernova â„ï¸ğŸŒŸ

**Glacial Supernova**ëŠ” Ray RLlibê³¼ PPO(Proximal Policy Optimization) ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ê°œë°œëœ ê³ ì„±ëŠ¥ **Heads-Up No-Limit Texas Hold'em (HUNL)** AI í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

Self-Play ê°•í™”í•™ìŠµê³¼ **Potential-Based Reward Shaping (PBRS)**ë¥¼ í†µí•´ GTO(Game Theory Optimal)ì— ê·¼ì ‘í•œ ì „ëµì„ í•™ìŠµí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## ğŸš€ ì£¼ìš” íŠ¹ì§•

### í•µì‹¬ ê¸°ìˆ 
*   **Multi-Agent Self-Play**: Self-Play í™˜ê²½(`MultiAgentEnv`)ìœ¼ë¡œ ì„¤ê³„ë˜ì–´, AIê°€ ìê¸° ìì‹ ê³¼ ëŒ€ê²°í•˜ë©° ì§€ì†ì ìœ¼ë¡œ ë°œì „
*   **Masked LSTM Architecture**: ë¶ˆê°€ëŠ¥í•œ ì•¡ì…˜ì„ ì›ì²œ ì°¨ë‹¨í•˜ëŠ” Action Maskingê³¼ LSTM ë„¤íŠ¸ì›Œí¬ ê²°í•©
*   **Potential-Based Reward Shaping (PBRS)**: ìˆ˜í•™ì ìœ¼ë¡œ ê²€ì¦ëœ ë³´ìƒ ì‹œìŠ¤í…œìœ¼ë¡œ í•™ìŠµ íš¨ìœ¨ ê·¹ëŒ€í™”
*   **Rich Observation Space**: 176ì°¨ì›ì˜ ì •êµí•œ ê´€ì°° ë²¡í„° (ì¹´ë“œ, ê²Œì„ ìƒíƒœ, í¬ì§€ì…˜, ì•¡ì…˜ íˆìŠ¤í† ë¦¬ í¬í•¨)
*   **Robust Stack Sampling**: ë§¤ í•¸ë“œë§ˆë‹¤ ìŠ¤íƒ ê¹Šì´ë¥¼ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ ë²”ìš©ì ì¸ ì „ëµ í•™ìŠµ

### PBRS ë³´ìƒ ì‹œìŠ¤í…œ
í”„ë¡œì íŠ¸ì˜ í•µì‹¬ í˜ì‹ ìœ¼ë¡œ, ë‹¤ìŒ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì™„ë²½íˆ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤:

1. âœ… **Effective Stack Normalization** - ìŠ¤íƒ ê¹Šì´ì— ë¬´ê´€í•œ ë³´ìƒ
2. âœ… **Terminal Î¦ Subtraction** - ìµœì¢… ë³´ìƒì—ì„œ í¬í…ì…œ ì°¨ê°
3. âœ… **Initial Î¦ Compensation** - ë¸”ë¼ì¸ë“œë¡œ ì¸í•œ ì´ˆê¸° ë¹„ëŒ€ì¹­ ë³´ì •
4. âœ… **Dual Reward Update** - Actorì™€ Observer ëª¨ë‘ì—ê²Œ ë³´ìƒ ì œê³µ
5. âœ… **Last Action Reward** - Fold/Showdown ì•¡ì…˜ì˜ ë³´ìƒ í¬í•¨
6. âœ… **Phantom Potential Fix** - Folded í”Œë ˆì´ì–´ì˜ ì˜ëª»ëœ í¬í…ì…œ ìˆ˜ì •
7. âœ… **Zero-Sum Verification** - ë§¤ í•¸ë“œ zero-sum ì†ì„± ê²€ì¦ (tolerance: 0.1)

**ê²°ê³¼**: ìˆ˜í•™ì ìœ¼ë¡œ ì™„ë²½í•œ zero-sum ë³´ìƒ ì‹œìŠ¤í…œ (violation < 0.001)

---

## ğŸ› ï¸ ì„¤ì¹˜

### ìš”êµ¬ì‚¬í•­
- Python 3.10 ì´ìƒ ê¶Œì¥
- Windows/Linux/Mac ì§€ì›

### ì„¤ì¹˜ ë‹¨ê³„

1. **ì €ì¥ì†Œ í´ë¡  ë° ê°€ìƒí™˜ê²½ ìƒì„±**
   ```bash
   # Windows
   py -3.11 -m venv venv
   .\\venv\\Scripts\\activate
   ```

2. **ì˜ì¡´ì„± ì„¤ì¹˜**
   ```bash
   pip install -r requirements.txt
   ```

3. **GPU ê°€ì† (ì„ íƒì‚¬í•­)**
   ```bash
   pip uninstall torch torchvision torchaudio
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

**ì£¼ìš” ì˜ì¡´ì„±:**
- `ray[rllib]` - ê°•í™”í•™ìŠµ í”„ë ˆì„ì›Œí¬
- `torch` - ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
- `gymnasium` - RL í™˜ê²½ í‘œì¤€
- `numpy` - ìˆ˜ì¹˜ ì—°ì‚°

---

## ğŸƒ ì‚¬ìš©ë²•

### 1. í•™ìŠµ ì‹œì‘

**ê¸°ë³¸ ì‹¤í–‰:**
```bash
python poker_rl/train.py
```

**ì‹¤í—˜ ì´ë¦„ ì§€ì • (ê¶Œì¥):**
```bash
python poker_rl/train.py --name omega
```

**í•™ìŠµ ì¬ê°œ:**
```bash
python poker_rl/train.py --name omega --resume
```

**í•™ìŠµ ì„¤ì •:**
- Train batch size: 8,192
- Environment workers: 4
- Gamma (Î³): 0.99
- Learning rate: 3e-4
- LSTM cell size: 256

### 2. í•™ìŠµ ëª¨ë‹ˆí„°ë§

**TensorBoard ì‹¤í–‰:**
```bash
# ìƒˆ í„°ë¯¸ë„
.\\venv\\Scripts\\activate
tensorboard --logdir experiments/logs
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:6006` ì ‘ì†

**ì£¼ìš” ë©”íŠ¸ë¦­:**
- `episode_reward_mean` - í‰ê·  ì—í”¼ì†Œë“œ ë³´ìƒ (0 ê·¼ì²˜ ìˆ˜ë ´)
- `policy_loss` - ì •ì±… ì†ì‹¤
- `value_loss` - ê°€ì¹˜ í•¨ìˆ˜ ì†ì‹¤
- `entropy` - íƒí—˜ ì •ë„

### 3. ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬

**ìë™ ì €ì¥ ì„¤ì •:**
- 10 iterationë§ˆë‹¤ ìë™ ì €ì¥
- ìµœê·¼ 5ê°œ ì²´í¬í¬ì¸íŠ¸ ìœ ì§€
- í•™ìŠµ ì¢…ë£Œ ì‹œ ìë™ ì €ì¥

**ì €ì¥ ìœ„ì¹˜:**
```
experiments/logs/<ì‹¤í—˜ëª…>/PPO_poker_env_<ID>/checkpoint_<iteration>/
```

**ìµœì‹  ì²´í¬í¬ì¸íŠ¸ í™•ì¸:**
```powershell
Get-ChildItem \"experiments\\logs\\<ì‹¤í—˜ëª…>\\PPO_poker_env_*\\checkpoint_*\" -Directory | 
    Sort-Object CreationTime -Descending | 
    Select-Object -First 1
```

### 4. AIì™€ ëŒ€ì „

**ê°„ë‹¨í•œ ëŒ€ì „ (Random/Call Station ë´‡):**
```bash
# Random ë´‡
python poker_rl/play_human.py --opponent random

# Call Station ë´‡
python poker_rl/play_human.py --opponent call_station
```

**í•™ìŠµëœ RL ëª¨ë¸ê³¼ ëŒ€ì „:**
```bash
# ëŒ€í™”í˜• ëª¨ë“œ
python play_vs_ai.py

# íŠ¹ì • ì‹¤í—˜ ì§€ì •
python play_vs_ai.py --model omega
```

**ì£¼ì˜:** í˜„ì¬ observation spaceê°€ 176ì°¨ì›ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ, ìƒˆë¡œ í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸ë§Œ í˜¸í™˜ë©ë‹ˆë‹¤.

---

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
glacial-supernova/
â”œâ”€â”€ poker_rl/                    # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ agents/                  # ë²¤ì¹˜ë§ˆí¬ ì—ì´ì „íŠ¸
â”‚   â”œâ”€â”€ models/                  # ì‹ ê²½ë§ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ masked_lstm.py      # LSTM + Action Masking
â”‚   â”‚   â””â”€â”€ masked_mlp.py       # MLP + Action Masking
â”‚   â”œâ”€â”€ utils/                   # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ obs_builder.py      # Observation ë¹Œë” (176ì°¨ì›)
â”‚   â”‚   â””â”€â”€ equity_calculator.py # Hand strength ê³„ì‚°
â”‚   â”œâ”€â”€ env.py                   # PokerMultiAgentEnv (PBRS êµ¬í˜„)
â”‚   â”œâ”€â”€ potential_state.py       # Î¦ ê³„ì‚°
â”‚   â””â”€â”€ train.py                 # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ POKERENGINE/                 # ì»¤ìŠ¤í…€ í¬ì»¤ ì—”ì§„
â”œâ”€â”€ experiments/                 # í•™ìŠµ ë¡œê·¸ ë° ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ play_vs_ai.py               # AI ëŒ€ì „ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ requirements.txt             # ì˜ì¡´ì„±
```

---

## ğŸ¯ Observation Space (176ì°¨ì›)

### êµ¬ì„± ìš”ì†Œ

**1. ì¹´ë“œ ì¸ì½”ë”© (0-118): 119ì°¨ì›**
- í™€ì¹´ë“œ 2ì¥: 34ì°¨ì›
- ì»¤ë®¤ë‹ˆí‹° 5ì¥: 85ì°¨ì›
- ê° ì¹´ë“œ: Rank (13) + Suit (4) one-hot
- **Suit Canonicalization ì ìš©**: ë¬´ëŠ¬ ëŒ€ì¹­ì„± ì œê±°ë¡œ 4ë°° í•™ìŠµ íš¨ìœ¨ í–¥ìƒ

**2. ê²Œì„ ìƒíƒœ (119-134): 16ì°¨ì›**
```
[119-124] Stacks, Pot, Bets (ë¡œê·¸ ìŠ¤ì¼€ì¼ ì •ê·œí™”)
[125] Button Position
[126] Street (preflop/flop/turn/river)
[127-128] Pot Odds, SPR
[129-134] Min Raise, Opponent Info
```

**3. Expert Features (135-142): 8ì°¨ì›**
```
[135] Hand Strength (Equity)
[136] Positive Potential (ê°œì„  í™•ë¥ )
[137] Negative Potential (ì•…í™” í™•ë¥ )
[138] Hand Index (ì¡±ë³´ ID, 0-168)
[139-142] Street Indicators
```

**4. Padding (143-149): 7ì°¨ì›**
- í–¥í›„ í™•ì¥ì„ ìœ„í•œ ì˜ˆì•½ ê³µê°„

**5. Street History (150-165): 16ì°¨ì›**
- ê° ìŠ¤íŠ¸ë¦¿ë³„ (4 streets Ã— 4 features):
  - Raise íšŸìˆ˜
  - Aggressor (ëˆ„ê°€ ê³µê²©ì ì´ì—ˆëŠ”ì§€)
  - íˆ¬ì ê¸ˆì•¡
  - 3-bet ì´ìƒ ì—¬ë¶€

**6. Current Street Context (166-171): 6ì°¨ì›**
- í˜„ì¬ ìŠ¤íŠ¸ë¦¿ ì•¡ì…˜ íŒ¨í„´
- ì—­í•  ì „í™˜ (Check-Raise ë“±)

**7. Investment Info (172-173): 2ì°¨ì›**
- ì´ íˆ¬ì ê¸ˆì•¡
- íˆ¬ì ë¹„ìœ¨ (Pot Commitment)

**8. Position Info (174-175): 2ì°¨ì›**
- IP/OOP ìœ„ì¹˜
- Postflop Position Advantage

---

## ğŸ® ì•¡ì…˜ ê³µê°„ (14 Actions)

```
[0] Fold
[1] Check/Call (context-sensitive)
[2] Min Raise
[3-12] Pot % Raise (10%, 25%, 33%, 50%, 75%, 100%, 125%, 150%, 200%, 300%)
[13] All-in
```

**Action Masking**: ë¶ˆê°€ëŠ¥í•œ ì•¡ì…˜ì€ ìë™ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ë˜ì–´ ì„ íƒ ë¶ˆê°€

---

## ğŸ“Š í•™ìŠµ ì„±ëŠ¥

### í˜„ì¬ ìƒíƒœ (PBRS êµ¬í˜„ í›„)
- **Zero-sum compliance**: < 0.001 (ê±°ì˜ ì™„ë²½)
- **Observation richness**: 176ì°¨ì› (ì•¡ì…˜ íˆìŠ¤í† ë¦¬ í¬í•¨)
- **Expected training**: 1-3M stepsë¡œ ê¸°ë³¸ ì „ëµ í•™ìŠµ ì˜ˆìƒ
  - ì´ì „ (ì•¡ì…˜ íˆìŠ¤í† ë¦¬ ì—†ìŒ): 5-10M steps í•„ìš”

### ê°œì„  íš¨ê³¼
- **Suit Canonicalization**: 4ë°° í•™ìŠµ ì†ë„ í–¥ìƒ
- **Action History**: 5-10ë°° ì „ëµ í•™ìŠµ ê°€ì†
- **PBRS**: ìˆ˜í•™ì ìœ¼ë¡œ ì™„ë²½í•œ ë³´ìƒ ì‹ í˜¸

---

## ğŸ”¬ ê¸°ìˆ  ì„¸ë¶€ì‚¬í•­

### PBRS (Potential-Based Reward Shaping)

**í•µì‹¬ ê³µì‹:**
```
Intermediate Reward = Î³ Ã— Î¦(s') - Î¦(s)
Terminal Reward = chip_change/eff_stack - Î¦_final + Î¦_initial

Total = Î£ Intermediate + Terminal
      = chip_change/eff_stack (telescoping sum)
```

**Dual Reward Update:**
- Actorì™€ Observer ëª¨ë‘ ë§¤ stepë§ˆë‹¤ ë³´ìƒ ìˆ˜ë ¹
- Multi-agent PBRSì˜ í•µì‹¬: í•œ í”Œë ˆì´ì–´ì˜ ì•¡ì…˜ì´ ì–‘ í”Œë ˆì´ì–´ì˜ í¬í…ì…œì— ì˜í–¥

**Î¦ (Potential) ê³„ì‚°:**
```python
equity = get_equity(cards, board)
expected_value = equity Ã— pot
risk_adjusted = expected_value - Î± Ã— invested
normalized = clip(risk_adjusted / effective_stack, -1, 1)
```

### Zero-Sum ê²€ì¦
ë§¤ í•¸ë“œ ì¢…ë£Œ ì‹œ:
```python
total_P0 + total_P1 == 0 (within tolerance 0.1)
```

Violation ë°œìƒ ì‹œ ì—ëŸ¬ë¡œ í•™ìŠµ ì¤‘ë‹¨ â†’ ì½”ë“œ ì˜¤ë¥˜ ì¦‰ì‹œ íƒì§€

---

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```python
# PPO
train_batch_size = 8192       # Reduced for faster iterations
gamma = 0.99                  # Discount factor
lr = 3e-4                     # Learning rate
clip_param = 0.2              # PPO clip
lambda_ = 0.95                # GAE lambda
entropy_coeff = 0.05          # Exploration
num_epochs = 10               # PPO epochs

# LSTM
lstm_cell_size = 256          # Hidden state size
max_seq_len = 40              # Max hand length

# Environment
num_env_runners = 4           # Parallel workers
sample_timeout_s = 300        # Timeout per sample
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì²´í¬í¬ì¸íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ
- `num_to_keep > 0` í™•ì¸ (í˜„ì¬: 5)
- `export_native_model_files=True` í™•ì¸

### Observation shape ë¶ˆì¼ì¹˜ ì—ëŸ¬
- êµ¬ ì²´í¬í¬ì¸íŠ¸ (150ì°¨ì›)ì™€ ì‹  ì½”ë“œ (176ì°¨ì›) ë¹„í˜¸í™˜
- í•´ê²°: ìƒˆë¡œ í•™ìŠµ ì‹œì‘

### Zero-sum violation ì—ëŸ¬
- Tolerance 0.1ë¡œ ì„¤ì •ë¨
- Gamma íš¨ê³¼ë¡œ ì¸í•œ ìì—°ìŠ¤ëŸ¬ìš´ violation (~0.001)
- 0.1 ì´ˆê³¼ ì‹œ ì½”ë“œ ë²„ê·¸ ì˜ì‹¬

### í•™ìŠµ ì†ë„ ëŠë¦¼
- GPU ì‚¬ìš© í™•ì¸: `torch.cuda.is_available()`
- Worker ìˆ˜ ì¡°ì •: `num_env_runners`
- Batch size ì¡°ì •: `train_batch_size`

---

## ğŸ“š ì°¸ê³  ìë£Œ

### PBRS ì´ë¡ 
- Ng et al. (1999): "Policy Invariance Under Reward Shaping"
- Wiewiora et al. (2003): "Principled Methods for Advising Reinforcement Learning Agents"

### í¬ì»¤ AI
- **DeepStack** (2017): Limited-depth search + deep learning
- **Pluribus** (2019): CFR + deep RL (6-player)
- **Rebel** (2020): CFR + self-play

### Multi-Agent RL
- RLlib Multi-Agent Documentation
- Multi-Agent PBRS extensions

---

## ğŸ›¤ï¸ ë¡œë“œë§µ

### ì™„ë£Œ âœ…
- [x] PBRS ì™„ì „ êµ¬í˜„
- [x] 176ì°¨ì› Observation space
- [x] Action history í†µí•©
- [x] Suit canonicalization
- [x] Zero-sum ê²€ì¦
- [x] Dual reward update

### ì§„í–‰ ì¤‘ ğŸ”„
- [ ] 1-3M steps í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
- [ ] GTO solverì™€ì˜ ë¹„êµ
- [ ] Exploitability ì¸¡ì •

### í–¥í›„ ê³„íš ğŸ“…
- [ ] Attention mechanism ë„ì…
- [ ] CFR integration
- [ ] Multi-stack range training
- [ ] Human vs AI í† ë„ˆë¨¼íŠ¸

---

## ğŸ’¡ ê¸°ì—¬ ê°€ì´ë“œ

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒì„ í™˜ì˜í•©ë‹ˆë‹¤:
- ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ìˆ˜ì •
- ì„±ëŠ¥ ê°œì„  ì œì•ˆ
- ìƒˆë¡œìš´ feature ì œì•ˆ
- ë¬¸ì„œ ê°œì„ 

---

## ğŸ“œ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.

---

**Glacial Supernova** - *Cold calculation, Explosive results.* â„ï¸ğŸŒŸ
